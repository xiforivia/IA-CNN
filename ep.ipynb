{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 2s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images: contém imagens de treinamento e rótulos de treinamento\n",
    "# test_images: verificaremos se nosso modelo também funciona bem\n",
    "# test_images: os dados de teste são usados ​​para ver o quão bem a máquina pode prever novas respostas com base em seu aprendizado\n",
    "# test_labels: rótulos de teste\n",
    "\n",
    "# 0 representa preto\n",
    "# 255 representa branco\n",
    "# o intervalo entre 0 e 255 são tons de cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[1,:,:], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[2,:,:], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#cada imagem tem seu valor correspondente:\n",
    "print(train_labels[1], train_labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ter certeza que keras é capaz de ler nossas imagens e usá-las efetivamente, precisamos remodelar as imagens \n",
    "# para uma dimensão, em vez de duas, multiplicando 28 por 28, então precisamos também escalar os valores \n",
    "# no intervalo [0, 1] primeiro transformando em float32 e dividindo pelo valor mais alto que é 255.\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images - train_images.astype(\"float32\")/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outra transformação que precisa ser feita antes de iniciar nosso treinamento é codificar categoricamente os rótulos,\n",
    "# a maneira mais fácil é usar o keras que fornece um método to_categorical \n",
    "# que pode ser usado para codificar dados inteiros de forma one-hot. \n",
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nosso modelo será um modelo sequencial que é apropriado para nosso exemplo onde cada camada tem  \n",
    "# exatamente um tensor de entrada e um tensor de saída. As camadas são os blocos básicos de construção da rede neural.\n",
    "# Uma camada consiste em uma função data in data out, em nosso exemplo usaremos  \n",
    "# duas camadas que estão densamente conectadas ou totalmente conectadas, uma camada densa alimenta tudo  \n",
    "# saída da camada anterior para todos os seus neurônios cada neurônio fornece uma saída para a próxima camada  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a primeira camada contém 512 unidades e como função de ativação usamos a função relu ou  \n",
    "# a unidade linear retificada e finalmente a forma de entrada de nossas imagens. \n",
    "model.add(layers.Dense(512, activation=\"relu\", input_shape = (28*28, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A segunda camada contém 10 unidades que representam as classes de 10 dígitos de 0 a 9, pois estamos fazendo uma \n",
    "# classificação multiclasse e lidando com probabilidade, então é preferível usar softmax como função de ativação.  \n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# na primeira camada temos 401920 parâmetros, que é o número total de pesos e viés, pois nossas camadas estão totalmente conectadas  \n",
    "# o número total de pesos é 28 vezes 28 entradas vezes 512 unidades mais 512 bias  \n",
    "# então para a segunda camada temos 5130 parâmetros que é o resultado do número total de pesos\n",
    "# 512 entradas vezes 10 unidades mais 10 bias.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O próximo passo é a compilação onde precisamos especificar \n",
    "# o otimizador que define como o modelo se atualizará usaremos o algoritmo rmsprop  \n",
    "# precisamos também especificar a função de perda (loss) que mede o desempenho nos dados de treinamento e  \n",
    "# usaremos para o nosso caso a entropia cruzada (crossentropy) e então precisamos especificar as métricas para monitorar\n",
    "# durante o treinamento e o teste, no nosso caso vamos focar apenas na acurácia que é o\n",
    "# número de imagens rotuladas corretamente de todos os dados\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics= [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 7s 13ms/step - loss: 5.5201 - accuracy: 0.8998\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.7241 - accuracy: 0.9543\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.4745 - accuracy: 0.9663\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 4s 9ms/step - loss: 0.3549 - accuracy: 0.9733\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 5s 10ms/step - loss: 0.2971 - accuracy: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d900343e50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# então deixamos nosso modelo aprender com o dados de treinamento usando o método fit,\n",
    "# o argumento necessário são as train_images, os train_labels, os número de épocas e o número de tamanho do batch.\n",
    "# uma época é uma passagem para frente e uma passagem para trás de todas as imagens de treinamento, no nosso caso faremos 5 vezes\n",
    "# e o tamanho do lote é o número dos exemplos de treinamento em um caminho para frente e para trás,\n",
    "# quanto maior o tamanho do batch, mais memória e espaço necessário, então decidimos prosseguir com um lote de 128\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 1.8589 - accuracy: 0.9503\n",
      "test_loss: 1.8588980436325073 \n",
      "test_acc: 0.9502999782562256\n",
      "Essa acurácia significa que o modelo é capaz de classificar corretamente 95.0%  das imagens\n"
     ]
    }
   ],
   "source": [
    "# Então, vamos verificar agora se nosso modelo executa também bem no test_images.\n",
    "# Os dados de teste são usados para ver o quão bem a máquina pode prever \n",
    "# novas respostas com base em seu treinamento, usando o método de avaliação, podemos obter o loss e a acurácia\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"test_loss:\", test_loss, \"\\ntest_acc:\", test_acc)\n",
    "print(f\"Essa acurácia significa que o modelo é capaz de classificar corretamente {round(test_acc*100, 1)}%  das imagens\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rede neural convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diferença entre camada densamente conectada e camada convolucional:\n",
    "# as camadas densas só podem aprender com os padrões globais de todos os pixels, mas o  \n",
    "# camada convolucional pode aprender com os padrões locais, por exemplo, ele pode olhar para a forma  \n",
    "# das bordas para as linhas verticais e/ou horizontais e então ele pode reconhecê-lo em qualquer lugar  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000,28,28,1))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28,28,1))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nosso modelo é um modelo sequencial que é apropriado para nosso exemplo onde cada camada  \n",
    "# tem exatamente uma resposta de entrada e uma resposta de saída\n",
    "model_conv = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as camadas conv consistem em um conjunto de filtros e  \n",
    "# cada filtro pode detectar um padrão específico em nosso exemplo usaremos o filtro 3x3 na primeira camada  \n",
    "# usaremos 32 filtros diferentes de 3x3 e a saída será 26 por 26 pixels e não 28 por 28 devido ao efeito da borda\n",
    "model_conv.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape = (28,28,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# então usamos o método de agrupamento máximo para  \n",
    "# para reduzir o tamanho de nossa entrada e também porque os pixels vizinhos nas imagens tendem a ter valores semelhantes\n",
    "# O max pooling, que é uma operação máxima simples que seleciona o valor máximo de um bloco de tensor.\n",
    "# No nosso exemplo, aplicaremos o pooling máximo 2 por 2, o que significa selecionar o  \n",
    "# valor máximo de cada bloco de 2 por 2 então a saída será 13 por 13 que é a metade da nossa entrada 26 por 26 \n",
    "model_conv.add(layers.MaxPooling2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# então usamos a segunda camada conv e desta vez usaremos 64 filtros diferentes e a saída será 11 por 11\n",
    "model_conv.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "# novamente usaremos o pooling máximo 2x2 e a saída será 5x5  \n",
    "model_conv.add(layers.MaxPooling2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e para a última camada de conv, usaremos 64 filtros\n",
    "model_conv.add(layers.Conv2D(64,(3,3), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para usar nosso primeiro modelo de arquitetura com duas camadas densas, precisamos nivelar a saída três por três vezes 64\n",
    "model_conv.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalmente, pode-se usar a mesma arquitetura do nosso primeiro modelo com duas camadas densas,\n",
    "# a primeira camada contém 64 unidades e a segunda contém 10 unidades que representam as 10 classes de dígitos de 0 a 9.\n",
    "model_conv.add(layers.Dense(64,activation = 'relu'))\n",
    "model_conv.add(layers.Dense(10, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o próximo passo é a fase de compilação onde precisamos especificar o otimizador  \n",
    "# que define como o modelo se atualizará, usaremos o algoritmo rmsprop para a função loss,  \n",
    "# que mede o desempenho nos dados de treinamento e usaremos a crossentropy \n",
    "# e as métricas para monitorar durante o treinamento e o teste \n",
    "# neste caso, focaremos apenas na acurácia, que é o número de imagens rotuladas corretamente  \n",
    "model_conv.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 35s 36ms/step - loss: 0.1936 - accuracy: 0.9400\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.0491 - accuracy: 0.9845\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 35s 38ms/step - loss: 0.0333 - accuracy: 0.9894\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 0.0249 - accuracy: 0.9924\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 32s 34ms/step - loss: 0.0211 - accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15843c46dd0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finalmente, deixamos nosso modelo aprender com os dados de treinamento usando o método fit. \n",
    "# Os argumentos necessários são as imagens do treino, os rótulos co treino, o número de épocas e o número do tamanho do lote.  \n",
    "# Uma época é uma passagem para frente e uma passagem para trás de todas as imagens de treinamento, em nosso caso,\n",
    "# faremos 5 vezes. O tamanho do batch é o número de exemplos de treinamento em uma passagem para frente e para trás quanto maior  \n",
    "# quanto maior for o tamanho do lote, mais espaço de memória será necessário, portanto, em nosso exemplo, selecionaremos um lote de 64.\n",
    "model_conv.fit(train_images, train_labels, epochs=5, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos verificar agora se nosso novo modelo também funciona bem nas imagens de teste.\n",
    "# Os dados de teste são usados para ver o quão bem a máquina pode prever novas respostas com base em seu treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0364 - accuracy: 0.9898\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_conv.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alcançamos 99% de precisão adicionando a camada conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.03636791929602623 \n",
      "test_acc: 0.989799976348877\n",
      "Essa acurácia significa que o modelo usando a camada conv é capaz de classificar corretamente 99.0%  das imagens\n"
     ]
    }
   ],
   "source": [
    "print(\"test_loss:\", test_loss, \"\\ntest_acc:\", test_acc)\n",
    "print(f\"Essa acurácia significa que o modelo usando a camada conv é capaz de classificar corretamente {round(test_acc*100, 1)}%  das imagens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Keras, to add a convolutional layer, you write model.add(Conv2D(filters=48,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "# What do all these terms mean?\n",
    "\n",
    "# filters is the number of desired feature maps.\n",
    "\n",
    "# kernel_size is the size of the convolution kernel. A single number 5 means a 5x5 convolution.\n",
    "\n",
    "# strides the new layer maps will have a size equal to the previous layer maps divided by strides. Leaving this blank results in strides=1.\n",
    "\n",
    "# padding is either 'same' or 'valid'. Leaving this blank results in padding='valid'. If padding is 'valid' then the size of the new layer maps is reduced by kernel_size-1. For example, if you perform a 5x5 convolution on a 28x28 image (map) with padding='valid', then the next layer has maps of size 24x24. If padding is 'same', then the size isn't reduced.\n",
    "\n",
    "# activation is applied during forward propagation. Leaving this blank results in no activation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import pandas as pd\n",
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def criar_modelo2():\n",
    "#     model_conv = models.Sequential()\n",
    "#     model_conv.add(layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, padding='valid', activation='relu', input_shape = (28,28,1)))\n",
    "#     model_conv.add(layers.MaxPooling2D((2,2)))\n",
    "#     model_conv.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "#     model_conv.add(layers.MaxPooling2D((2,2)))\n",
    "#     model_conv.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "#     model_conv.add(layers.Flatten())\n",
    "#     model_conv.add(layers.Dense(64,activation = 'relu'))\n",
    "#     model_conv.add(layers.Dense(10, activation= 'softmax'))\n",
    "#     return model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento():\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    train_images = train_images.reshape((60000,28,28,1))\n",
    "    train_images = train_images.astype('float32')/255\n",
    "\n",
    "    test_images = test_images.reshape((10000,28,28,1))\n",
    "    test_images = test_images.astype('float32')/255\n",
    "\n",
    "    train_labels = to_categorical(train_labels)\n",
    "    test_labels = to_categorical(test_labels)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a arquitetura da CNN\n",
    "def criar_modelo(conv_layers, filters, dense_size):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Adicionar camadas de convolução-pooling\n",
    "    for _ in range(conv_layers):\n",
    "        model.add(keras.layers.Conv2D(filters=filters, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "        model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(dense_size, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax')) # 10 é o número de classes\n",
    "    \n",
    "    # model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.fit(train_images, train_labels, epochs=5, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x0000015843F29C60>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juju_\\OneDrive\\Documentos\\Sistemas-de-Informação\\5-Semestre\\IA\\EP1\\ep.ipynb Cell 43\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#Y101sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model \u001b[39m=\u001b[39m criar_modelo(conv_layers, filters, dense_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#Y101sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#Y101sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(model, train_images, train_labels, cv\u001b[39m=\u001b[39;49mkfold, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:59\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m---> 59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:268\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:79\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     74\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     80\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[0;32m     84\u001b[0m             )\n\u001b[0;32m     86\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[0;32m     87\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x0000015843F29C60>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "\n",
    "train_images, train_labels, test_images, test_labels = pre_processamento()\n",
    "\n",
    "# Definir os valores fixos dos parâmetros\n",
    "filters = 32\n",
    "kernel_size = (3, 3)\n",
    "strides = (1, 1)\n",
    "padding = 'same'\n",
    "dense_size = 128\n",
    "\n",
    "# Testar diferentes quantidades de camadas de convolução-pooling\n",
    "conv_layers_list = [1, 2, 3]\n",
    "accuracies_conv_layers = []\n",
    "\n",
    "for conv_layers in conv_layers_list:\n",
    "    model = criar_modelo(conv_layers, filters, dense_size)\n",
    "    kfold = KFold(n_splits=5)\n",
    "    scores = cross_val_score(model, train_images, train_labels, cv=kfold, scoring='accuracy')\n",
    "    # accuracies_conv_layers.append(scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x0000015843F58A90>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juju_\\OneDrive\\Documentos\\Sistemas-de-Informação\\5-Semestre\\IA\\EP1\\ep.ipynb Cell 43\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X64sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     model \u001b[39m=\u001b[39m criar_modelo(conv_layers, filters, dense_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X64sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     kfold \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X64sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     scores \u001b[39m=\u001b[39m cross_val_score(model, train_images, train_labels, cv\u001b[39m=\u001b[39;49mkfold, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X64sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     accuracies_conv_layers\u001b[39m.\u001b[39mappend(scores\u001b[39m.\u001b[39mmean())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X64sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Identificar a melhor quantidade de camadas de convolução-pooling\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:59\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m---> 59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:268\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:79\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     74\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     80\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[0;32m     84\u001b[0m             )\n\u001b[0;32m     86\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[0;32m     87\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x0000015843F58A90>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# # Carregar os dados do Fashion MNIST\n",
    "# fashion_mnist = keras.datasets.fashion_mnist\n",
    "# (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# # Pré-processamento dos dados\n",
    "# train_images = train_images.reshape(-1, 28, 28, 1) / 255.0\n",
    "# test_images = test_images.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = pre_processamento()\n",
    "\n",
    "# Definir os valores fixos dos parâmetros\n",
    "filters = 32\n",
    "kernel_size = (3, 3)\n",
    "strides = (1, 1)\n",
    "padding = 'same'\n",
    "dense_size = 128\n",
    "\n",
    "# Testar diferentes quantidades de camadas de convolução-pooling\n",
    "conv_layers_list = [1, 2, 3]\n",
    "accuracies_conv_layers = []\n",
    "\n",
    "for conv_layers in conv_layers_list:\n",
    "    model = criar_modelo(conv_layers, filters, dense_size)\n",
    "    kfold = KFold(n_splits=5)\n",
    "    scores = cross_val_score(model, train_images, train_labels, cv=kfold, scoring='accuracy')\n",
    "    accuracies_conv_layers.append(scores.mean())\n",
    "\n",
    "# Identificar a melhor quantidade de camadas de convolução-pooling\n",
    "best_conv_layers = conv_layers_list[np.argmax(accuracies_conv_layers)]\n",
    "best_accuracy_conv_layers = accuracies_conv_layers[np.argmax(accuracies_conv_layers)]\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"A. Comparação da acurácia para diferentes quantidades de camadas de convolução-pooling:\")\n",
    "for i, conv_layers in enumerate(conv_layers_list):\n",
    "    print(\"Quantidade de camadas de convolução-pooling: {}\".format(conv_layers))\n",
    "    print(\"Acurácia média: {:.4f}\".format(accuracies_conv_layers[i]))\n",
    "    print()\n",
    "    \n",
    "print(\"A melhor quantidade de camadas de convolução-pooling é: {}\".format(best_conv_layers))\n",
    "print(\"A melhor acurácia média é: {:.4f}\".format(best_accuracy_conv_layers))\n",
    "print()\n",
    "\n",
    "# Considerando a melhor quantidade de camadas de convolução-pooling, testar diferentes quantidades de filters\n",
    "filters_list = [16, 32, 64]\n",
    "accuracies_filters = []\n",
    "\n",
    "for filters in filters_list:\n",
    "    model = criar_modelo(best_conv_layers, filters, dense_size)\n",
    "    kfold = KFold(n_splits=5)\n",
    "    scores = cross_val_score(model, train_images, train_labels, cv=kfold, scoring='accuracy')\n",
    "    accuracies_filters.append(scores.mean())\n",
    "\n",
    "# Identificar a melhor quantidade de filters\n",
    "best_filters = filters_list[np.argmax(accuracies_filters)]\n",
    "best_accuracy_filters = accuracies_filters[np.argmax(accuracies_filters)]\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"B. Comparação da acurácia para diferentes quantidades de filters:\")\n",
    "for i, filters in enumerate(filters_list):\n",
    "    print(\"Quantidade de filters na camada de convolução: {}\".format(filters))\n",
    "    print(\"Acurácia média: {:.4f}\".format(accuracies_filters[i]))\n",
    "    print()\n",
    "    \n",
    "print(\"A melhor quantidade de filters na camada de convolução é: {}\".format(best_filters))\n",
    "print(\"A melhor acurácia média é: {:.4f}\".format(best_accuracy_filters))\n",
    "print()\n",
    "\n",
    "# Considerando a melhor quantidade de camadas de convolução-pooling e a melhor quantidade de filters, testar diferentes tamanhos de dense_size\n",
    "dense_size_list = [64, 128, 256]\n",
    "accuracies_dense_size = []\n",
    "\n",
    "for dense_size in dense_size_list:\n",
    "    model = criar_modelo(best_conv_layers, best_filters, dense_size)\n",
    "    kfold = KFold(n_splits=5)\n",
    "    scores = cross_val_score(model, train_images, train_labels, cv=kfold, scoring='accuracy')\n",
    "    accuracies_dense_size.append(scores.mean())\n",
    "\n",
    "# Identificar o melhor tamanho da camada densa\n",
    "best_dense_size = dense_size_list[np.argmax(accuracies_dense_size)]\n",
    "best_accuracy_dense_size = accuracies_dense_size[np.argmax(accuracies_dense_size)]\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"C. Comparação da acurácia para diferentes tamanhos de camada densa:\")\n",
    "for i, dense_size in enumerate(dense_size_list):\n",
    "    print(\"Tamanho da camada densa: {}\".format(dense_size))\n",
    "    print(\"Acurácia média: {:.4f}\".format(accuracies_dense_size[i]))\n",
    "    print()\n",
    "    \n",
    "print(\"O melhor tamanho da camada densa é: {}\".format(best_dense_size))\n",
    "print(\"A melhor acurácia média é: {:.4f}\".format(best_accuracy_dense_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar diferentes configurações usando cross-validation\n",
    "parameters = {\n",
    "    'conv_layers': [1, 2, 3],\n",
    "    'filters': [16, 32, 64],\n",
    "    'dense_size': [64, 128, 256]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x000001584386F1F0>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:862\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     tasks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ready_batches\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    863\u001b[0m \u001b[39mexcept\u001b[39;00m queue\u001b[39m.\u001b[39mEmpty:\n\u001b[0;32m    864\u001b[0m     \u001b[39m# slice the iterator n_jobs * batchsize items at a time. If the\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     \u001b[39m# slice returns less than that, then the current batchsize puts\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[39m# accordingly to distribute evenly the last items between all\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[39m# workers.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\queue.py:168\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qsize():\n\u001b[1;32m--> 168\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juju_\\OneDrive\\Documentos\\Sistemas-de-Informação\\5-Semestre\\IA\\EP1\\ep.ipynb Cell 39\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X52sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mfit(train_images, train_labels, epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X52sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Realizar cross-validation com 5 folds\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X52sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(model, train_images, train_labels, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X52sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m mean_accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(scores)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juju_/OneDrive/Documentos/Sistemas-de-Informa%C3%A7%C3%A3o/5-Semestre/IA/EP1/ep.ipynb#X52sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m mean_accuracy \u001b[39m>\u001b[39m best_accuracy:\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:873\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    870\u001b[0m n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_effective_n_jobs\n\u001b[0;32m    871\u001b[0m big_batch_size \u001b[39m=\u001b[39m batch_size \u001b[39m*\u001b[39m n_jobs\n\u001b[1;32m--> 873\u001b[0m islice \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(itertools\u001b[39m.\u001b[39;49mislice(iterator, big_batch_size))\n\u001b[0;32m    874\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(islice) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    875\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:59\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m---> 59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:268\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m--> 268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juju_\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:79\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     74\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mYou should provide an instance of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     76\u001b[0m                 \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mscikit-learn estimator instead of a class.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     80\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mCannot clone object \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m): \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mit does not seem to be a scikit-learn \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mestimator as it does not implement a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget_params\u001b[39m\u001b[39m'\u001b[39m\u001b[39m method.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(estimator), \u001b[39mtype\u001b[39m(estimator))\n\u001b[0;32m     84\u001b[0m             )\n\u001b[0;32m     86\u001b[0m klass \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\n\u001b[0;32m     87\u001b[0m new_object_params \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mget_params(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x000001584386F1F0>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "best_parameters = {}\n",
    "\n",
    "for conv_layers in parameters['conv_layers']:\n",
    "    for filters in parameters['filters']:\n",
    "        for dense_size in parameters['dense_size']:\n",
    "            model = model_conv\n",
    "            model.fit(train_images, train_labels, epochs=5, verbose=0)\n",
    "\n",
    "            # Realizar cross-validation com 5 folds\n",
    "            scores = cross_val_score(model, train_images, train_labels, cv=5, scoring='accuracy')\n",
    "            mean_accuracy = np.mean(scores)\n",
    "\n",
    "            if mean_accuracy > best_accuracy:\n",
    "                best_accuracy = mean_accuracy\n",
    "                best_parameters = {'conv_layers': conv_layers, 'filters': filters, 'dense_size': dense_size}\n",
    "\n",
    "# Imprimir os melhores parâmetros encontrados\n",
    "print(\"Melhores parâmetros:\")\n",
    "print(best_parameters)\n",
    "print(\"Melhor acurácia:\")\n",
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
